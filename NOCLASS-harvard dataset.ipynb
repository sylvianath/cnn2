{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u_1XjXCfp1O2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import getDataMedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gDEYyXygp1PY"
   },
   "outputs": [],
   "source": [
    "senLen =7\n",
    "indexSize = None\n",
    "embeddingSize = 128\n",
    "kernelSizes = [3,4,5]\n",
    "numFilters = 3\n",
    "embeddings = None\n",
    "XY = None\n",
    "model = None\n",
    "lossFn = nn.CrossEntropyLoss().type(torch.FloatTensor)\n",
    "opt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SHCpP3-Bp1Pl"
   },
   "outputs": [],
   "source": [
    "def makeEmbeddings(numWords,index,X,senWords,embed):\n",
    "    inputData = torch.zeros([len(X),1,senWords,embeddingSize],dtype=torch.float64)\n",
    "    for i,sen in enumerate(X):\n",
    "        senIndex = torch.zeros([1,senWords,embeddingSize],dtype=torch.float64)\n",
    "        for j,word in enumerate(sen):\n",
    "            senIndex[0,j]= embed[j-1]\n",
    "        inputData[i][0] = Variable(torch.DoubleTensor(senIndex[0]))\n",
    "    return inputData\n",
    "\n",
    "def makeModel(lr):\n",
    "    model = nn.ModuleList([nn.Conv2d(1,200,(3,embeddingSize)),nn.Conv2d(200,300,(4,embeddingSize),nn.Conv2d(300,500),(5,1))])\n",
    "    '''model = nn.Sequential(\n",
    "            nn.Conv2d(1,200,kernel_size=(3,embeddingSize),stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(200,300,(4,1),stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(300),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(300,500,(5,1),stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(500),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.MaxPool2d((50,1)),\n",
    "            Flatten(), \n",
    "            nn.Linear(500,2),\n",
    "    )'''\n",
    "    opt = optim.Adam(model.parameters(),lr=lr)\n",
    "    return model,opt\n",
    "\n",
    "\n",
    "\n",
    "def train(numEpochs=1):\n",
    "    print(\"Model\",model)\n",
    "    bestAcc = 0\n",
    "    for epoch in range(numEpochs):\n",
    "        print(\"Epoch #\",epoch)\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for i,(x,y) in enumerate(XY):\n",
    "            xVar = Variable(x).float()\n",
    "            yVar = Variable(y).type(torch.LongTensor)\n",
    "            scores = model(xVar)\n",
    "            loss = lossFn(scores,yVar)\n",
    "            if i == 0: \n",
    "                print(\"i = %d, loss = %.4f\" % (i + 1, loss.data[0]))\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"i = %d, loss = %.4f \" % (i + 1, loss.data[0]))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            total_loss += loss.data[0] \n",
    "            opt.step()\n",
    "        currAcc = checkAccuracy(XY)\n",
    "        if currAcc > bestAcc: \n",
    "            bestAcc = currAcc\n",
    "            save_checkpoint(model,'model.pt')\n",
    "        \n",
    "        print(\"total_loss %.4f\"% total_loss/float(i))\n",
    "def checkAccuracy(dataSet):\n",
    "    #if(self.XY.dataset.train):\n",
    "    #    print('Checking accuracy on validation set')\n",
    "    #else:\n",
    "    #    print('Checking accuracy on test set')\n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    model.eval()\n",
    "    for i,(x,y) in enumerate(dataSet):\n",
    "        xVar = Variable(x).float()\n",
    "        yVar = Variable(y).type(torch.LongTensor)\n",
    "        scores = model(xVar)\n",
    "        _,preds = scores.data.cpu().max(1)\n",
    "        numCorrect += (preds == yVar).sum()\n",
    "        numSamples += preds.size(0)\n",
    "    acc = float(numCorrect)/numSamples\n",
    "    return acc\n",
    "    print('Got %d / %d correct (%.2f)' % (numCorrect, numSamples, 100 * acc))\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        N,C,H,W = x.size()\n",
    "        return x.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling getData...\n",
      "7.0 med\n",
      "16623\n"
     ]
    }
   ],
   "source": [
    "print('calling getData...')\n",
    "X,XTe,word_to_idx,XY,XYTe,Y,Yte,med = getDataMedian.runNew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1250,
     "status": "error",
     "timestamp": 1526945337230,
     "user": {
      "displayName": "Moshe Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112997361072337440949"
     },
     "user_tz": 420
    },
    "id": "k7netEw6p1P4",
    "outputId": "be0664bc-c5fb-4ffe-f69c-fe8f31a0a0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making embeddings...\n"
     ]
    }
   ],
   "source": [
    "print('making embeddings...')\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.randn(len(index)+1,128)\n",
    "for k,v in index.items():\n",
    "    try: \n",
    "        embeddings[v-1].copy_(torch.from_numpy(word_vectors.get_vector(k)))\n",
    "    except KeyError:\n",
    "        continue \n",
    "embeddings[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = makeEmbeddings(len(index),index,X,senLen,embeddings)\n",
    "inputDataTe = makeEmbeddings(len(index),index,Xte,senLen,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(index.keys())[0])\n",
    "print(list(indexTe.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yxNU7aMrp1QN",
    "outputId": "884a8cb2-7f03-4fec-e15a-08e302047d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model...\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print('making model...')\n",
    "model,opt=makeModel(lr=1e-4)\n",
    "print(type(inputData), type(Y))\n",
    "my_datasetTr = utils.TensorDataset(inputData, Y)\n",
    "my_datasetTe = utils.TensorDataset(inputDataTe, Yte)\n",
    "my_dataloaderTr = utils.DataLoader(my_datasetTr,batch_size=64)\n",
    "my_dataloaderTe = utils.DataLoader(my_datasetTe,batch_size=64)\n",
    "XY = my_dataloaderTr\n",
    "XYte = my_dataloaderTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LThDksKAp1Qc",
    "outputId": "745d86db-939e-4c94-a43e-27ce6167a0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling train...\n",
      "Model Sequential(\n",
      "  (0): Conv2d(1, 200, kernel_size=(3, 300), stride=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): Conv2d(200, 300, kernel_size=(4, 1), stride=(1, 1))\n",
      "  (5): ReLU(inplace)\n",
      "  (6): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): Dropout(p=0.2)\n",
      "  (8): Conv2d(300, 500, kernel_size=(5, 1), stride=(1, 1))\n",
      "  (9): ReLU(inplace)\n",
      "  (10): BatchNorm2d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (11): Dropout(p=0.2)\n",
      "  (12): MaxPool2d(kernel_size=(50, 1), stride=(50, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Flatten()\n",
      "  (14): Linear(in_features=500, out_features=2, bias=True)\n",
      ")\n",
      "Epoch # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1, loss = 1.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 100, loss = 0.5450 \n",
      "i = 200, loss = 0.2993 \n",
      "i = 300, loss = 0.6867 \n",
      "i = 400, loss = 0.5023 \n",
      "i = 500, loss = 0.3910 \n",
      "i = 600, loss = 0.3225 \n",
      "i = 700, loss = 0.5441 \n",
      "i = 800, loss = 0.4703 \n",
      "i = 900, loss = 0.7310 \n",
      "i = 1000, loss = 0.7975 \n",
      "i = 1100, loss = 0.5794 \n",
      "i = 1200, loss = 1.6852 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.Flatten'>: it's not the same object as __main__.Flatten",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7f36a5637904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'calling train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-af29c1535237>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(numEpochs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrAcc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbestAcc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mbestAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrAcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total_loss %.4f\"\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-1aa7af9cfd19>\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(state, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'checkpoint.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_storages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class '__main__.Flatten'>: it's not the same object as __main__.Flatten"
     ]
    }
   ],
   "source": [
    "print('calling train...')\n",
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sLpQ0CuLp1Qw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking training accuracy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4509037044736945"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('checking training accuracy...')\n",
    "checkAccuracy(XY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model,  'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking validation accuracy...\n",
      "Got 912 / 1821 correct (50.08)\n"
     ]
    }
   ],
   "source": [
    "print('checking validation accuracy...')\n",
    "checkAccuracy(my_dataloaderTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 100, loss = 9.7361\n",
      "i = 200, loss = 9.6903\n",
      "i = 300, loss = 9.7456\n",
      "i = 400, loss = 9.6905\n",
      "i = 500, loss = 9.6392\n",
      "i = 600, loss = 9.6411\n",
      "i = 700, loss = 9.6473\n",
      "i = 800, loss = 9.6686\n",
      "i = 900, loss = 9.6868\n",
      "i = 1000, loss = 9.7353\n",
      "i = 1100, loss = 9.6816\n",
      "i = 1200, loss = 9.5365\n",
      "Epoch # 1\n",
      "i = 100, loss = 9.6092\n",
      "i = 200, loss = 9.5382\n",
      "i = 300, loss = 9.6364\n",
      "i = 400, loss = 9.6277\n",
      "i = 500, loss = 9.5093\n",
      "i = 600, loss = 9.5198\n",
      "i = 700, loss = 9.6371\n",
      "i = 800, loss = 9.4575\n",
      "i = 900, loss = 9.5999\n",
      "i = 1000, loss = 9.6197\n",
      "i = 1100, loss = 9.5490\n",
      "i = 1200, loss = 9.4070\n",
      "Epoch # 2\n",
      "i = 100, loss = 9.5561\n",
      "i = 200, loss = 9.3913\n",
      "i = 300, loss = 9.5359\n",
      "i = 400, loss = 9.4710\n",
      "i = 500, loss = 9.4327\n",
      "i = 600, loss = 9.3857\n",
      "i = 700, loss = 9.4832\n",
      "i = 800, loss = 9.3978\n",
      "i = 900, loss = 9.5204\n",
      "i = 1000, loss = 9.5192\n",
      "i = 1100, loss = 9.4498\n",
      "i = 1200, loss = 9.2692\n",
      "Epoch # 3\n",
      "i = 100, loss = 9.3439\n",
      "i = 200, loss = 9.2677\n",
      "i = 300, loss = 9.4322\n",
      "i = 400, loss = 9.3178\n",
      "i = 500, loss = 9.2859\n",
      "i = 600, loss = 9.2316\n",
      "i = 700, loss = 9.5217\n",
      "i = 800, loss = 9.3323\n",
      "i = 900, loss = 9.3463\n",
      "i = 1000, loss = 9.4322\n",
      "i = 1100, loss = 9.2977\n",
      "i = 1200, loss = 9.2040\n",
      "Epoch # 4\n",
      "i = 100, loss = 9.3461\n",
      "i = 200, loss = 9.2312\n",
      "i = 300, loss = 9.4364\n",
      "i = 400, loss = 9.1798\n",
      "i = 500, loss = 9.1613\n",
      "i = 600, loss = 9.1147\n",
      "i = 700, loss = 9.4553\n",
      "i = 800, loss = 9.2595\n",
      "i = 900, loss = 9.3557\n",
      "i = 1000, loss = 9.3069\n",
      "i = 1100, loss = 9.2106\n",
      "i = 1200, loss = 9.0664\n"
     ]
    }
   ],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vGQaSi9Op1Q-",
    "outputId": "32448edc-7b74-46c1-d7a3-91691a8d1352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking training accuracy...\n",
      "Got 34702 / 76961 correct (45.09)\n",
      "checking validation accuracy...\n",
      "Got 912 / 1821 correct (50.08)\n"
     ]
    }
   ],
   "source": [
    "print('checking training accuracy...')\n",
    "checkAccuracy(XY)\n",
    "print('checking validation accuracy...')\n",
    "checkAccuracy(my_dataloaderTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dYClOdt5p1Ra"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 100, loss = 2.4784\n",
      "starting new epoch\n",
      "i = 100, loss = 1.9646\n",
      "starting new epoch\n",
      "i = 100, loss = 1.4863\n",
      "starting new epoch\n",
      "i = 100, loss = 2.7162\n",
      "starting new epoch\n",
      "i = 100, loss = 2.3571\n",
      "starting new epoch\n",
      "i = 100, loss = 2.9301\n",
      "starting new epoch\n",
      "i = 100, loss = 2.1042\n",
      "starting new epoch\n",
      "i = 100, loss = 1.2779\n",
      "starting new epoch\n",
      "i = 100, loss = 1.7552\n",
      "starting new epoch\n",
      "i = 100, loss = 0.8972\n",
      "starting new epoch\n",
      "i = 100, loss = 1.5916\n",
      "starting new epoch\n",
      "i = 100, loss = 1.3580\n",
      "starting new epoch\n",
      "i = 100, loss = 1.7536\n",
      "starting new epoch\n",
      "i = 100, loss = 1.9626\n",
      "starting new epoch\n",
      "i = 100, loss = 1.1654\n",
      "starting new epoch\n",
      "i = 100, loss = 2.0342\n",
      "starting new epoch\n",
      "i = 100, loss = 2.9617\n",
      "starting new epoch\n",
      "i = 100, loss = 1.3506\n",
      "starting new epoch\n",
      "i = 100, loss = 2.2686\n",
      "starting new epoch\n",
      "i = 100, loss = 2.3137\n",
      "starting new epoch\n",
      "i = 100, loss = 1.3706\n",
      "starting new epoch\n",
      "i = 100, loss = 1.8966\n",
      "starting new epoch\n",
      "i = 100, loss = 1.7058\n",
      "starting new epoch\n",
      "i = 100, loss = 1.8096\n",
      "starting new epoch\n",
      "i = 100, loss = 2.1094\n",
      "starting new epoch\n",
      "i = 100, loss = 2.5694\n",
      "starting new epoch\n",
      "i = 100, loss = 2.2970\n",
      "starting new epoch\n",
      "i = 100, loss = 2.1099\n",
      "starting new epoch\n",
      "i = 100, loss = 1.6030\n",
      "starting new epoch\n",
      "i = 100, loss = 1.8429\n",
      "starting new epoch\n",
      "i = 100, loss = 2.1024\n",
      "starting new epoch\n",
      "i = 100, loss = 2.0040\n",
      "starting new epoch\n",
      "i = 100, loss = 1.3669\n",
      "starting new epoch\n",
      "i = 100, loss = 1.7559\n",
      "starting new epoch\n",
      "i = 100, loss = 1.3153\n",
      "starting new epoch\n",
      "i = 100, loss = 1.4945\n",
      "starting new epoch\n",
      "i = 100, loss = 1.0583\n",
      "starting new epoch\n",
      "i = 100, loss = 2.3257\n",
      "starting new epoch\n",
      "i = 100, loss = 1.7808\n",
      "starting new epoch\n",
      "i = 100, loss = 2.2131\n",
      "starting new epoch\n",
      "i = 100, loss = 2.1122\n",
      "starting new epoch\n",
      "i = 100, loss = 1.7773\n",
      "starting new epoch\n",
      "i = 100, loss = 2.7236\n",
      "starting new epoch\n",
      "i = 100, loss = 1.8836\n",
      "starting new epoch\n",
      "i = 100, loss = 1.7409\n",
      "starting new epoch\n",
      "i = 100, loss = 1.8219\n",
      "starting new epoch\n",
      "i = 100, loss = 1.3425\n",
      "starting new epoch\n",
      "i = 100, loss = 2.2014\n",
      "starting new epoch\n",
      "i = 100, loss = 1.8657\n",
      "starting new epoch\n",
      "i = 100, loss = 1.2200\n",
      "starting new epoch\n"
     ]
    }
   ],
   "source": [
    "train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking training accuracy...\n",
      "Got 4954 / 8000 correct (61.92)\n",
      "checking validation accuracy...\n",
      "Got 142 / 2662 correct (5.33)\n"
     ]
    }
   ],
   "source": [
    "print('checking training accuracy...')\n",
    "checkAccuracy(XY)\n",
    "print('checking validation accuracy...')\n",
    "checkAccuracy(my_dataloaderTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0 / 1821 correct (0.00)\n"
     ]
    }
   ],
   "source": [
    "checkAccuracy(XYte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0 / 1821 correct (0.00)\n"
     ]
    }
   ],
   "source": [
    "checkAccuracy(my_dataloaderTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 0 / 76961 correct (0.00)\n"
     ]
    }
   ],
   "source": [
    "checkAccuracy(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkAccuracy(my_dataloaderTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "NOCLASS.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
