{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u_1XjXCfp1O2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as utils\n",
    "import getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gDEYyXygp1PY"
   },
   "outputs": [],
   "source": [
    "senLen = 7\n",
    "indexSize = 15144\n",
    "embeddingSize = 300\n",
    "kernelSizes = [3,4,5]\n",
    "numFilters = 3\n",
    "embeddings = None\n",
    "XY = None\n",
    "model = None\n",
    "lossFn = nn.CrossEntropyLoss().type(torch.FloatTensor)\n",
    "opt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeModel(lr):\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(1,200,kernel_size=(3,embeddingSize),stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.Dropout(p=0.2),\n",
    "            '''nn.Conv2d(200,300,(4,1),stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(300),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Conv2d(300,500,(5,1),stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(500),\n",
    "            nn.Dropout(p=0.2),'''\n",
    "            nn.MaxPool2d((50,1)),\n",
    "            Flatten(), \n",
    "            nn.Linear(500,2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SHCpP3-Bp1Pl"
   },
   "outputs": [],
   "source": [
    "def makeEmbeddings(numWords,index,X,senWords,embed):\n",
    "    inputData = torch.zeros([len(X),1,senWords,embeddingSize],dtype=torch.float64)\n",
    "    for i,sen in enumerate(X):\n",
    "        senIndex = torch.zeros([1,senWords,embeddingSize],dtype=torch.float64)\n",
    "        for j,word in enumerate(sen):\n",
    "            senIndex[0,j]= embed[j-1]\n",
    "        inputData[i][0] = Variable(torch.DoubleTensor(senIndex[0]))\n",
    "    return inputData\n",
    "\n",
    "def makeModel(lr):\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv2d(1,200,kernel_size=(3,embeddingSize),stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(200),\n",
    "            nn.Dropout(p=0.2),\n",
    "            Flatten(), \n",
    "            nn.Linear(1000,2),\n",
    "    )\n",
    "    opt = optim.Adam(model.parameters(),lr=lr)\n",
    "    return model,opt\n",
    "\n",
    "def train(numEpochs=1):\n",
    "    print(\"Model\",model)\n",
    "    bestAcc = 0\n",
    "    for epoch in range(numEpochs):\n",
    "        print(\"Epoch #\",epoch)\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for i,(x,y) in enumerate(XY):\n",
    "            xVar = Variable(x).float()\n",
    "            yVar = Variable(y).type(torch.LongTensor)\n",
    "            scores = model(xVar)\n",
    "            loss = lossFn(scores,yVar)\n",
    "            if i == 0: \n",
    "                print(\"i = %d, loss = %.4f\" % (i + 1, loss.data[0]))\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"i = %d, loss = %.4f \" % (i + 1, loss.data[0]))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            total_loss += loss.data[0] \n",
    "            opt.step()\n",
    "        currAcc = checkAccuracy(XY)\n",
    "        if currAcc > bestAcc: \n",
    "            bestAcc = currAcc\n",
    "            save_checkpoint(model,'model.pt')\n",
    "        l = float(total_loss/float(i))\n",
    "        print(\"total_loss %.4f\"% l)\n",
    "              \n",
    "def checkAccuracy(dataSet):\n",
    "    #if(self.XY.dataset.train):\n",
    "    #    print('Checking accuracy on validation set')\n",
    "    #else:\n",
    "    #    print('Checking accuracy on test set')\n",
    "    numCorrect = 0\n",
    "    numSamples = 0\n",
    "    model.eval()\n",
    "    for i,(x,y) in enumerate(dataSet):\n",
    "        xVar = Variable(x).float()\n",
    "        yVar = Variable(y).type(torch.LongTensor)\n",
    "        scores = model(xVar)\n",
    "        _,preds = scores.data.cpu().max(1)\n",
    "        numCorrect += (preds == yVar).sum()\n",
    "        numSamples += preds.size(0)\n",
    "    acc = float(numCorrect)/numSamples\n",
    "    return acc\n",
    "    print('Got %d / %d correct (%.2f)' % (numCorrect, numSamples, 100 * acc))\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self,x):\n",
    "        N,C,H,W = x.size()\n",
    "        return x.view(N,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling getData...\n",
      "med 7\n",
      "15144\n",
      "true\n",
      "max 7\n",
      "en 41646\n"
     ]
    }
   ],
   "source": [
    "print('calling getData...')\n",
    "X,index,XY,Y = getData.runTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-a826d48a6a09>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-a826d48a6a09>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Xte,XYte,Yte,max_sent_ = getData.getTest(index,max_sent_len)/\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Xte,XYte,Yte,max_sent_ = getData.getTest(index,max_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1250,
     "status": "error",
     "timestamp": 1526945337230,
     "user": {
      "displayName": "Moshe Yang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "112997361072337440949"
     },
     "user_tz": 420
    },
    "id": "k7netEw6p1P4",
    "outputId": "be0664bc-c5fb-4ffe-f69c-fe8f31a0a0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making embeddings...\n"
     ]
    }
   ],
   "source": [
    "print('making embeddings...')\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.randn(len(index)+1,300)\n",
    "for k,v in index.items():\n",
    "    try: \n",
    "        embeddings[v-1].copy_(torch.from_numpy(word_vectors.get_vector(k)))\n",
    "    except KeyError:\n",
    "        continue \n",
    "embeddings[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData = makeEmbeddings(len(index),index,X,senLen,embeddings)\n",
    "#inputDataTe = makeEmbeddings(len(index),index,Xte,senLen,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "yxNU7aMrp1QN",
    "outputId": "884a8cb2-7f03-4fec-e15a-08e302047d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making model...\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print('making model...')\n",
    "model,opt=makeModel(lr=.01)\n",
    "print(type(inputData), type(Y))\n",
    "my_datasetTr = utils.TensorDataset(inputData, Y)\n",
    "#my_datasetTe = utils.TensorDataset(inputDataTe, Yte)\n",
    "my_dataloaderTr = utils.DataLoader(my_datasetTr,batch_size=64)\n",
    "#my_dataloaderTe = utils.DataLoader(my_datasetTe,batch_size=64)\n",
    "XY = my_dataloaderTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LThDksKAp1Qc",
    "outputId": "745d86db-939e-4c94-a43e-27ce6167a0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling train...\n",
      "Model Sequential(\n",
      "  (0): Conv2d(1, 200, kernel_size=(3, 300), stride=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): Flatten()\n",
      "  (5): Linear(in_features=1000, out_features=2, bias=True)\n",
      ")\n",
      "Epoch # 0\n",
      "i = 1, loss = 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 100, loss = 0.6612 \n",
      "i = 200, loss = 0.4991 \n",
      "i = 300, loss = 0.4459 \n",
      "i = 400, loss = 0.6600 \n",
      "i = 500, loss = 0.6822 \n",
      "i = 600, loss = 0.6712 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss 0.6163\n",
      "Epoch # 1\n",
      "i = 1, loss = 1.9869\n",
      "i = 100, loss = 0.6105 \n",
      "i = 200, loss = 0.4933 \n",
      "i = 300, loss = 0.4365 \n",
      "i = 400, loss = 0.6395 \n",
      "i = 500, loss = 0.6150 \n",
      "i = 600, loss = 0.6637 \n",
      "total_loss 0.6049\n",
      "Epoch # 2\n",
      "i = 1, loss = 1.1358\n",
      "i = 100, loss = 0.6125 \n",
      "i = 200, loss = 0.4898 \n",
      "i = 300, loss = 0.4397 \n",
      "i = 400, loss = 0.6327 \n",
      "i = 500, loss = 0.6323 \n",
      "i = 600, loss = 0.6707 \n",
      "total_loss 0.5958\n",
      "Epoch # 3\n",
      "i = 1, loss = 1.4975\n",
      "i = 100, loss = 0.6022 \n",
      "i = 200, loss = 0.4936 \n",
      "i = 300, loss = 0.4434 \n",
      "i = 400, loss = 0.6482 \n",
      "i = 500, loss = 0.6234 \n",
      "i = 600, loss = 0.6672 \n",
      "total_loss 0.5989\n",
      "Epoch # 4\n",
      "i = 1, loss = 1.5042\n",
      "i = 100, loss = 0.6075 \n",
      "i = 200, loss = 0.4866 \n",
      "i = 300, loss = 0.4322 \n",
      "i = 400, loss = 0.6308 \n",
      "i = 500, loss = 0.6328 \n",
      "i = 600, loss = 0.6633 \n",
      "total_loss 0.5988\n"
     ]
    }
   ],
   "source": [
    "print('calling train...')\n",
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "save_checkpoint(model,  'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sLpQ0CuLp1Qw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking training accuracy...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4181433991259665"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('checking training accuracy...')\n",
    "checkAccuracy(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Sequential(\n",
      "  (0): Conv2d(1, 200, kernel_size=(3, 300), stride=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Dropout(p=0.2)\n",
      "  (4): Flatten()\n",
      "  (5): Linear(in_features=1000, out_features=2, bias=True)\n",
      ")\n",
      "Epoch # 0\n",
      "i = 1, loss = 1.5426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/user1/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 100, loss = 0.6253 \n",
      "i = 200, loss = 0.4849 \n",
      "i = 300, loss = 0.4332 \n",
      "i = 400, loss = 0.6334 \n",
      "i = 500, loss = 0.6193 \n",
      "i = 600, loss = 0.6602 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user1/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Flatten. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss 0.6006\n",
      "Epoch # 1\n",
      "i = 1, loss = 1.6935\n",
      "i = 100, loss = 0.6091 \n",
      "i = 200, loss = 0.4902 \n",
      "i = 300, loss = 0.4318 \n",
      "i = 400, loss = 0.6360 \n",
      "i = 500, loss = 0.6155 \n",
      "i = 600, loss = 0.6651 \n",
      "total_loss 0.6011\n",
      "Epoch # 2\n",
      "i = 1, loss = 1.5827\n",
      "i = 100, loss = 0.6157 \n",
      "i = 200, loss = 0.4714 \n",
      "i = 300, loss = 0.4359 \n",
      "i = 400, loss = 0.6391 \n",
      "i = 500, loss = 0.6238 \n",
      "i = 600, loss = 0.6657 \n",
      "total_loss 0.6012\n",
      "Epoch # 3\n",
      "i = 1, loss = 1.5415\n",
      "i = 100, loss = 0.6185 \n",
      "i = 200, loss = 0.4921 \n",
      "i = 300, loss = 0.4487 \n",
      "i = 400, loss = 0.6432 \n",
      "i = 500, loss = 0.6730 \n",
      "i = 600, loss = 0.6729 \n",
      "total_loss 0.6027\n",
      "Epoch # 4\n",
      "i = 1, loss = 1.4742\n",
      "i = 100, loss = 0.6134 \n",
      "i = 200, loss = 0.4878 \n",
      "i = 300, loss = 0.4304 \n",
      "i = 400, loss = 0.6412 \n",
      "i = 500, loss = 0.6287 \n",
      "i = 600, loss = 0.6678 \n",
      "total_loss 0.6013\n",
      "Epoch # 5\n",
      "i = 1, loss = 1.6975\n",
      "i = 100, loss = 0.6032 \n",
      "i = 200, loss = 0.4807 \n",
      "i = 300, loss = 0.4341 \n",
      "i = 400, loss = 0.6305 \n",
      "i = 500, loss = 0.6236 \n",
      "i = 600, loss = 0.6646 \n",
      "total_loss 0.6031\n",
      "Epoch # 6\n",
      "i = 1, loss = 1.5934\n",
      "i = 100, loss = 0.6223 \n",
      "i = 200, loss = 0.4813 \n",
      "i = 300, loss = 0.4396 \n",
      "i = 400, loss = 0.6330 \n",
      "i = 500, loss = 0.6642 \n",
      "i = 600, loss = 0.6646 \n",
      "total_loss 0.6021\n",
      "Epoch # 7\n",
      "i = 1, loss = 1.7724\n",
      "i = 100, loss = 0.6147 \n",
      "i = 200, loss = 0.4838 \n",
      "i = 300, loss = 0.4363 \n",
      "i = 400, loss = 0.6334 \n",
      "i = 500, loss = 0.6604 \n",
      "i = 600, loss = 0.6696 \n",
      "total_loss 0.6022\n",
      "Epoch # 8\n",
      "i = 1, loss = 1.5994\n",
      "i = 100, loss = 0.6066 \n",
      "i = 200, loss = 0.4970 \n",
      "i = 300, loss = 0.4429 \n",
      "i = 400, loss = 0.6390 \n",
      "i = 500, loss = 0.6385 \n",
      "i = 600, loss = 0.6654 \n",
      "total_loss 0.6026\n",
      "Epoch # 9\n",
      "i = 1, loss = 1.7306\n",
      "i = 100, loss = 0.6139 \n",
      "i = 200, loss = 0.5021 \n",
      "i = 300, loss = 0.4474 \n",
      "i = 400, loss = 0.6252 \n",
      "i = 500, loss = 0.6249 \n",
      "i = 600, loss = 0.6650 \n",
      "total_loss 0.6029\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4181433991259665"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkAccuracy(XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking validation accuracy...\n",
      "Got 912 / 1821 correct (50.08)\n"
     ]
    }
   ],
   "source": [
    "print('checking validation accuracy...')\n",
    "checkAccuracy(my_dataloaderTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "NOCLASS.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
